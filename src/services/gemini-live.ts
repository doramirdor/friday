import { DatabaseService } from './database';
import { Buffer } from 'buffer';

// Add global error handler for unhandled crashes
if (typeof window !== 'undefined') {
  window.addEventListener('error', (event) => {
    if (event.error && event.error.stack && event.error.stack.includes('gemini-live')) {
      console.error('üö® GEMINI LIVE CRASH DETECTED:', {
        message: event.error.message,
        stack: event.error.stack,
        filename: event.filename,
        lineno: event.lineno,
        colno: event.colno,
        timestamp: new Date().toISOString()
      });
    }
  });

  window.addEventListener('unhandledrejection', (event) => {
    if (event.reason && event.reason.stack && event.reason.stack.includes('gemini-live')) {
      console.error('üö® GEMINI LIVE UNHANDLED REJECTION:', {
        reason: event.reason.message || event.reason,
        stack: event.reason.stack,
        timestamp: new Date().toISOString()
      });
    }
  });
  
  // Add additional monitoring for any crashes
  console.log('üîç GLOBAL: Gemini Live global error handlers installed');
  
  // Add process crash detection for Electron renderer
  if (typeof process !== 'undefined') {
    process.on('uncaughtException', (err) => {
      console.error('[renderer] uncaught exception:', err);
    });
    
    process.on('unhandledRejection', (err) => {
      console.error('[renderer] unhandled rejection:', err);
    });
  }
}

// Environment-based logging control
const isDevelopment = process.env.NODE_ENV === 'development';
const debugLog = (...args: unknown[]) => {
  if (isDevelopment) {
    console.log(...args);
  }
};

const debugWarn = (...args: unknown[]) => {
  if (isDevelopment) {
    console.warn(...args);
  }
};

// Interface for Gemini Live streaming results
export interface GeminiLiveResult {
  transcript: string;
  isFinal: boolean;
  speakerTag?: number;
  confidence?: number;
}

// Interface for Gemini Live options
export interface GeminiLiveOptions {
  sampleRateHertz?: number;
  encoding?: 'LINEAR16' | 'FLAC' | 'MULAW' | 'AMR' | 'AMR_WB' | 'OGG_OPUS' | 'SPEEX_WITH_HEADER_BYTE';
  enableSpeakerDiarization?: boolean;
  maxSpeakerCount?: number;
  languageCode?: string;
}



// Interface for Gemini Live response
interface GeminiLiveResponse {
  setupComplete?: boolean;
  serverContent?: {
    modelTurn?: {
      parts: Array<{
        text?: string;
        inlineData?: {
          mimeType: string;
          data: string;
        };
      }>;
    };
    inputTranscription?: {
      text: string;
      finished?: boolean;
    };
    outputTranscription?: {
      text: string;
      finished?: boolean;
    };
    turnComplete?: boolean;
    interrupted?: boolean;
    generationComplete?: boolean;
  };
  toolCall?: {
    functionCalls: Array<{
      id: string;
      name: string;
      args: Record<string, unknown>;
    }>;
  };
  toolCallCancellation?: {
    ids: string[];
  };
  usageMetadata?: {
    totalTokenCount: number;
    promptTokenCount: number;
    responseTokenCount: number;
  };
  goAway?: {
    timeLeft: string;
  };
  sessionResumptionUpdate?: {
    newHandle: string;
    resumable: boolean;
  };
  error?: {
    message: string;
    code?: number;
  };
}

// Interface for the Gemini Live service
export interface GeminiLiveService {
  isAvailable: boolean;
  isStreaming: boolean;
  startStreaming: (options?: GeminiLiveOptions) => Promise<void>;
  stopStreaming: () => void;
  onResult: (callback: (result: GeminiLiveResult) => void) => void;
  onError: (callback: (error: Error) => void) => void;
  cleanup: () => void;
}

class GeminiLiveServiceImpl implements GeminiLiveService {
  private websocket: WebSocket | null = null;
  private audioStream: MediaStream | null = null;
  private resultCallback: ((result: GeminiLiveResult) => void) | null = null;
  private errorCallback: ((error: Error) => void) | null = null;
  private _isStreaming = false;
  private _isAvailable = false;
  private apiKey: string | null = null;
  private audioChunksBuffer: Blob[] = [];
  private processingInterval: number | null = null;
  private audioAccumulationBuffer: Blob[] = [];
  private lastProcessTime = 0;
  private readonly ACCUMULATION_TIME_MS = 500;
  private audioContext: AudioContext | null = null;
  private audioProcessor: ScriptProcessorNode | null = null;
  private messageCount = 0;

  constructor() {
    console.log('üîç CONSTRUCTOR: Initializing GeminiLiveServiceImpl...');
    this.checkAvailability();
    console.log('üîç CONSTRUCTOR: checkAvailability called');
    
    // Add buffer monitoring for crash prevention
    // if (isDevelopment) {
    //   setInterval(() => {
    //     debugLog('üîç BUFFER MONITOR:', {
    //       accumulation: this.audioAccumulationBuffer?.length || 0,
    //       processing: this.audioChunksBuffer?.length || 0,
    //       isStreaming: this._isStreaming,
    //       timestamp: new Date().toISOString()
    //     });
    //   }, 5000);
    // }
  }

  private async checkAvailability() {
    console.log('üîç AVAILABILITY: Starting availability check...');
    
    try {
      // Check if we have the necessary APIs
      const hasWebSocket = typeof WebSocket !== 'undefined';
      const hasAudioContext = typeof AudioContext !== 'undefined';
      const hasGetUserMedia = !!(navigator.mediaDevices?.getUserMedia);

      console.log('üîç AVAILABILITY: API checks:', {
        hasWebSocket,
        hasAudioContext,
        hasGetUserMedia
      });

      // Get API key from various sources
      const electronAPI = (window as { electronAPI?: { env?: { GEMINI_API_KEY?: string } } }).electronAPI;
      const envApiKey = electronAPI?.env?.GEMINI_API_KEY;
      
      let settingsApiKey = null;
      try {
        const settings = await DatabaseService.getSettings();
        settingsApiKey = settings?.geminiApiKey;
        console.log('üîç AVAILABILITY: Database settings loaded, has API key:', !!settingsApiKey);
      } catch (dbError) {
        console.warn('üîç AVAILABILITY: Could not access database for API key:', dbError);
      }
      
      const localStorageApiKey = localStorage.getItem('gemini-api-key');
      
      this.apiKey = envApiKey || settingsApiKey || localStorageApiKey;

      console.log('üîç AVAILABILITY: API key sources:', {
        envApiKey: !!envApiKey,
        settingsApiKey: !!settingsApiKey,
        localStorageApiKey: !!localStorageApiKey,
        finalApiKey: !!this.apiKey
      });

      this._isAvailable = hasWebSocket && hasAudioContext && hasGetUserMedia && !!this.apiKey;

      console.log('üîç AVAILABILITY: Final availability result:', this._isAvailable);

      if (!this._isAvailable) {
        console.warn('üîç AVAILABILITY: Gemini Live not available:', {
          hasWebSocket,
          hasAudioContext,
          hasGetUserMedia,
          hasApiKey: !!this.apiKey
        });
      } else {
        console.log('üîç AVAILABILITY: Gemini Live service available');
      }
    } catch (error) {
      console.error('üîç AVAILABILITY: Error checking Gemini Live availability:', error);
      this._isAvailable = false;
    }
  }

  get isAvailable(): boolean {
    return this._isAvailable;
  }

  get isStreaming(): boolean {
    return this._isStreaming;
  }

  async startStreaming(options: GeminiLiveOptions = {}): Promise<void> {
    console.log('üöÄ GEMINI LIVE: Starting streaming with crash detection...');
    console.log('üîç IMMEDIATE: startStreaming method called with options:', options);
    console.log('üîç IMMEDIATE: Current service state:', {
      isAvailable: this._isAvailable,
      isStreaming: this._isStreaming,
      hasApiKey: !!this.apiKey
    });
    
    // Add a simple test mode flag
    const testMode = localStorage.getItem('gemini-live-test-mode') === 'true';
    console.log('üîç IMMEDIATE: Test mode check:', testMode);
    
    if (testMode) {
      console.log('üß™ TEST MODE: Starting simplified Gemini Live test...');
      return this.startTestMode(options);
    }
    
    // Add comprehensive crash detection
    const crashDetector = {
      step: 'initialization',
      startTime: Date.now(),
      log: (step: string, data?: unknown) => {
        crashDetector.step = step;
        console.log(`üîç GEMINI LIVE STEP [${step}]:`, data || '');
      },
      error: (step: string, error: Error | unknown) => {
        const errorMessage = error instanceof Error ? error.message : String(error);
        const errorStack = error instanceof Error ? error.stack : undefined;
        console.error(`üö® GEMINI LIVE CRASH at [${step}]:`, {
          error: errorMessage,
          stack: errorStack,
          step,
          timeElapsed: Date.now() - crashDetector.startTime,
          timestamp: new Date().toISOString()
        });
      }
    };

    try {
      crashDetector.log('availability-check');
      if (!this._isAvailable) {
        throw new Error('Gemini Live service is not available');
      }

      crashDetector.log('streaming-check');
      if (this._isStreaming) {
        console.warn('Gemini Live streaming is already active');
        return;
      }

      crashDetector.log('api-key-check');
      if (!this.apiKey) {
        throw new Error('Gemini API key not configured. Please add your API key in settings.');
      }

      crashDetector.log('options-setup');
      // Default options
      const defaultOptions: Required<GeminiLiveOptions> = {
        sampleRateHertz: 16000,
        encoding: 'LINEAR16',
        enableSpeakerDiarization: true,
        maxSpeakerCount: 4,
        languageCode: 'en-US',
        ...options
      };

      crashDetector.log('microphone-capture-start', defaultOptions);
      // Start microphone capture
      await this.startMicrophoneCapture(defaultOptions);

      // Add a small delay to ensure audio processing is fully initialized
      console.log('‚è±Ô∏è Adding delay before WebSocket connection...');
      await new Promise(resolve => setTimeout(resolve, 100));
      console.log('‚è±Ô∏è Delay completed, proceeding with WebSocket connection');

      crashDetector.log('websocket-connect-start');
      // Connect to Gemini Live WebSocket
      await this.connectWebSocket(defaultOptions);

      crashDetector.log('streaming-state-update');
      this._isStreaming = true;
      
      crashDetector.log('success', { timeElapsed: Date.now() - crashDetector.startTime });
      console.log('‚úÖ Gemini Live streaming started successfully');

      // Verify audio processing is actually working
      setTimeout(() => {
        console.log('üîç AUDIO VERIFICATION: Checking if audio processing started...');
        console.log('üîç AUDIO VERIFICATION: Buffer size:', this.audioAccumulationBuffer?.length || 0);
        console.log('üîç AUDIO VERIFICATION: AudioContext state:', this.audioContext?.state);
        console.log('üîç AUDIO VERIFICATION: Processing interval active:', !!this.processingInterval);
      }, 2000);
      
      console.log('üîç POST-STARTUP: Service initialized successfully, starting monitoring...');
      
      // Check service state every 500ms for the first 10 seconds
      let monitoringCount = 0;
      const monitoringInterval = setInterval(() => {
        monitoringCount++;
        console.log(`üîç POST-STARTUP MONITOR #${monitoringCount}:`, {
          isStreaming: this._isStreaming,
          websocketState: this.websocket?.readyState,
          audioContextState: this.audioContext?.state,
          processingIntervalActive: !!this.processingInterval,
          timestamp: new Date().toISOString()
        });
        
        // Stop monitoring after 20 checks (10 seconds)
        if (monitoringCount >= 20) {
          clearInterval(monitoringInterval);
          console.log('üîç POST-STARTUP: Monitoring completed - service appears stable');
        }
      }, 500);
    } catch (error) {
      crashDetector.error(crashDetector.step, error);
      console.error('‚ùå Failed to start Gemini Live streaming:', error);
      
      // Enhanced cleanup with crash detection
      try {
        crashDetector.log('cleanup-after-error');
        this.cleanup();
      } catch (cleanupError) {
        console.error('üö® CLEANUP CRASH:', cleanupError);
      }
      
      throw error;
    }
  }

  private async startMicrophoneCapture(options: Required<GeminiLiveOptions>): Promise<void> {
    try {
      console.log('üé§ Starting microphone capture for Gemini Live...');
      
      // Check if microphone access is available
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('Microphone access not available in this browser');
      }

      // Get microphone access with 16kHz sample rate to match Gemini Live API requirements
      console.log('üé§ Requesting microphone permission...');
      this.audioStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000, // Fixed to 16kHz for Gemini Live API compatibility
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });

      console.log('‚úÖ Microphone access granted');

      // Check if AudioContext is available
      if (typeof AudioContext === 'undefined') {
        throw new Error('AudioContext not available in this browser');
      }

      // Instead of using MediaRecorder, use Web Audio API to capture raw PCM data directly
      // This eliminates the need for WebM-to-PCM conversion
      console.log('üé§ Creating AudioContext...');
      const audioContext = new AudioContext({
        sampleRate: 16000 // Match Gemini Live API requirements
      });

      // Check if AudioContext was created successfully
      if (!audioContext) {
        throw new Error('Failed to create AudioContext');
      }

      console.log('‚úÖ AudioContext created successfully');

      const source = audioContext.createMediaStreamSource(this.audioStream);
      
      // Create a ScriptProcessorNode to capture raw audio data
      // Note: ScriptProcessorNode is deprecated but still widely supported
      // We'll use it for now as AudioWorklet requires more complex setup
      const bufferSize = 4096; // Process in 4KB chunks
      const processor = audioContext.createScriptProcessor(bufferSize, 1, 1);
      
      let audioEventCount = 0;
      
      processor.onaudioprocess = (event) => {
        try {
          audioEventCount++;
          
          // Always log the first few events to verify audio processing is working
          if (audioEventCount <= 10) {
            console.log(`üé§ AUDIO EVENT #${audioEventCount} - ScriptProcessorNode firing`);
          }
          
          // Add crash detection wrapper
          const crashDetector = {
            step: 'audio-event-start',
            log: (step: string) => {
              crashDetector.step = step;
              if (audioEventCount <= 5) {
                debugLog(`üé§ AUDIO CRASH DETECTOR [${step}] event #${audioEventCount}`);
              }
            }
          };
          
          crashDetector.log('input-buffer-check');
          const inputBuffer = event.inputBuffer;
          if (!inputBuffer) {
            if (audioEventCount <= 3) {
              debugWarn('‚ö†Ô∏è No input buffer in audio event');
            }
            return;
          }
          
          crashDetector.log('channel-data-get');
          const inputData = inputBuffer.getChannelData(0); // Get mono channel (Float32Array)
          
          if (!inputData || inputData.length === 0) {
            if (audioEventCount <= 3) {
              debugWarn('‚ö†Ô∏è No input data or empty input data');
            }
            return;
          }
          
          crashDetector.log('audio-level-calculation');
          // Only calculate audio level occasionally to reduce CPU usage
          let audioLevel = 0;
          let hasAudioActivity = false;
          if (audioEventCount <= 3 || audioEventCount % 1000 === 1) {
            audioLevel = this.calculateAudioLevel(inputData);
            hasAudioActivity = audioLevel > 0.001;
            debugLog(`üé§ Processing ${inputData.length} audio samples, level: ${audioLevel.toFixed(6)}, hasActivity: ${hasAudioActivity}`);
          }
          
          crashDetector.log('pcm-conversion-start');
          // Convert Float32Array to 16-bit PCM
          const pcmData = new Int16Array(inputData.length);
          
          crashDetector.log('pcm-conversion-loop');
          for (let i = 0; i < inputData.length; i++) {
            const sample = Math.max(-1, Math.min(1, inputData[i]));
            pcmData[i] = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
          }
          
          crashDetector.log('blob-creation');
          // Add PCM data directly to accumulation buffer
          const pcmBlob = new Blob([pcmData.buffer]);
          
          crashDetector.log('buffer-push');
          this.audioAccumulationBuffer.push(pcmBlob);
          
          // Always log buffer growth for first few events
          if (audioEventCount <= 10) {
            console.log(`üé§ BUFFER: Added chunk ${pcmData.byteLength} bytes, total buffer size: ${this.audioAccumulationBuffer.length}`);
          }
          
          crashDetector.log('logging-check');
          if (audioEventCount <= 3 || audioEventCount % 1000 === 1) {
            debugLog(`üé§ Raw PCM chunk captured: ${pcmData.byteLength} bytes, buffer size: ${this.audioAccumulationBuffer.length}`);
          }
          
          crashDetector.log('audio-event-complete');
        } catch (processingError) {
          console.error(`üö® CRASH in audio processing event #${audioEventCount}:`, {
            error: processingError.message,
            stack: processingError.stack,
            timestamp: new Date().toISOString(),
            step: (processingError as Error & { step?: string }).step || 'unknown'
          });
          
          // Try to continue processing despite the error
          if (this.errorCallback) {
            this.errorCallback(new Error(`Audio processing error: ${processingError.message}`));
          }
        }
      };
      
      // Connect the audio processing chain
      try {
        source.connect(processor);
        processor.connect(audioContext.destination);
        console.log('‚úÖ Audio processing chain connected');
      } catch (connectionError) {
        console.error('Error connecting audio processing chain:', connectionError);
        throw new Error(`Failed to connect audio processing chain: ${connectionError.message}`);
      }
      
      // Store references for cleanup
      this.audioContext = audioContext;
      this.audioProcessor = processor;

      console.log('üé§ Direct PCM capture started at 16kHz for Gemini Live API');
      console.log('üé§ AudioContext sample rate:', audioContext.sampleRate);
      
      // Add immediate audio processing test
      console.log('üé§ Testing audio processing pipeline...');
      let audioTestPassed = false;
      try {
        // Test if the audio processing chain is working
        if (this.audioAccumulationBuffer && Array.isArray(this.audioAccumulationBuffer)) {
          console.log('üé§ Audio accumulation buffer is ready');
          audioTestPassed = true;
        } else {
          console.warn('‚ö†Ô∏è Audio accumulation buffer is not properly initialized');
        }
      } catch (audioTestError) {
        console.error('üö® Audio processing test failed:', audioTestError);
      }
      
      console.log('üé§ Audio processing test result:', audioTestPassed ? 'PASSED' : 'FAILED');
      
      // Add diagnostic check for audio processing events
      setTimeout(() => {
        console.log('üîç AUDIO DIAGNOSTIC: Checking if audio events are being triggered...');
        console.log('üîç AUDIO DIAGNOSTIC: Audio event count so far:', audioEventCount);
        console.log('üîç AUDIO DIAGNOSTIC: Audio context state:', audioContext.state);
        console.log('üîç AUDIO DIAGNOSTIC: Audio stream tracks:', this.audioStream?.getTracks().length || 0);
        
        if (this.audioStream) {
          this.audioStream.getTracks().forEach((track, index) => {
            console.log(`üîç AUDIO DIAGNOSTIC: Track ${index}:`, {
              kind: track.kind,
              enabled: track.enabled,
              readyState: track.readyState,
              muted: track.muted
            });
          });
        }
        
        if (audioEventCount === 0) {
          console.warn('‚ö†Ô∏è AUDIO DIAGNOSTIC: No audio events triggered yet - this may indicate an issue with the audio processing chain');
        } else {
          console.log('‚úÖ AUDIO DIAGNOSTIC: Audio events are being triggered successfully');
        }
      }, 3000);
      
    } catch (error) {
      console.error('Failed to start microphone capture:', error);
      
      // Clean up any partially created resources
      this.cleanup();
      
      // Provide more specific error messages
      if (error.name === 'NotAllowedError') {
        throw new Error('Microphone permission denied. Please allow microphone access and try again.');
      } else if (error.name === 'NotFoundError') {
        throw new Error('No microphone found. Please connect a microphone and try again.');
      } else if (error.name === 'NotSupportedError') {
        throw new Error('Microphone access not supported in this browser.');
      } else if (error.name === 'NotReadableError') {
        throw new Error('Microphone is already in use by another application.');
      } else {
        throw new Error(`Microphone access failed: ${error.message}`);
      }
    }
  }

  private async connectWebSocket(options: Required<GeminiLiveOptions>): Promise<void> {
    return new Promise((resolve, reject) => {
      try {
        console.log('üîó Connecting to Gemini Live WebSocket...');
        
        // Check WebSocket availability
        if (typeof WebSocket === 'undefined') {
          reject(new Error('WebSocket is not available in this environment'));
          return;
        }
        console.log('üîó WebSocket constructor is available');
        
        if (!this.apiKey) {
          reject(new Error('API key is required for WebSocket connection'));
          return;
        }
        console.log('üîó API key is available');

        const wsUrl = `wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1beta.GenerativeService.BidiGenerateContent?key=${this.apiKey}`;
        console.log('üîó WebSocket URL:', wsUrl.replace(this.apiKey, '[API_KEY_HIDDEN]'));
        
        console.log('üîó Creating WebSocket instance...');
        try {
          this.websocket = new WebSocket(wsUrl);
          console.log('üîó WebSocket instance created successfully');
          console.log('üîó WebSocket readyState:', this.websocket.readyState);
          console.log('üîó WebSocket URL property:', this.websocket.url ? this.websocket.url.replace(this.apiKey, '[API_KEY_HIDDEN]') : 'undefined');
          
          // Check for immediate errors
          setTimeout(() => {
            if (this.websocket?.readyState === WebSocket.CLOSED) {
              console.error('üö® WebSocket closed immediately after creation!');
            }
          }, 100);
          
        } catch (wsCreationError) {
          console.error('üö® CRASH during WebSocket creation:', {
            error: wsCreationError.message,
            stack: wsCreationError.stack,
            url: wsUrl.replace(this.apiKey, '[API_KEY_HIDDEN]'),
            timestamp: new Date().toISOString()
          });
          reject(new Error(`Failed to create WebSocket: ${wsCreationError.message}`));
          return;
        }

        console.log('üîó Setting up connection timeout...');
        // Set up connection timeout
        const connectionTimeout = setTimeout(() => {
          console.log('üîó Connection timeout triggered');
          if (this.websocket && this.websocket.readyState === WebSocket.CONNECTING) {
            console.error('‚ùå WebSocket connection timeout');
            this.websocket.close();
            reject(new Error('Connection timeout - please check your internet connection and API key'));
          }
        }, 10000); // 10 second timeout

        console.log('üîó Setting up WebSocket event handlers...');
        
        try {
          console.log('üîó Setting up onopen handler...');
          this.websocket.onopen = () => {
            try {
              console.log('üîó WebSocket onopen event triggered');
              console.log('üîó Gemini Live WebSocket connected');
              clearTimeout(connectionTimeout);
              
              console.log('üîó Sending initial configuration...');
              // Send initial configuration
              this.sendInitialConfig(options);
              console.log('üîó Initial configuration sent successfully');
              
              console.log('üîó Starting audio processing...');
              // Start processing audio chunks
              this.startAudioProcessing();
              console.log('üîó Audio processing started successfully');
              
              console.log('üîó WebSocket setup complete, resolving promise');
              resolve();
              
              // Verify audio processing is actually working
              setTimeout(() => {
                console.log('üîç AUDIO VERIFICATION: Checking if audio processing started...');
                console.log('üîç AUDIO VERIFICATION: Buffer size:', this.audioAccumulationBuffer?.length || 0);
                console.log('üîç AUDIO VERIFICATION: AudioContext state:', this.audioContext?.state);
                console.log('üîç AUDIO VERIFICATION: Processing interval active:', !!this.processingInterval);
              }, 2000);
              
              console.log('üîç POST-STARTUP: Service initialized successfully, starting monitoring...');
              
              // Check service state every 500ms for the first 10 seconds
              let monitoringCount = 0;
              const monitoringInterval = setInterval(() => {
                monitoringCount++;
                console.log(`üîç POST-STARTUP MONITOR #${monitoringCount}:`, {
                  isStreaming: this._isStreaming,
                  websocketState: this.websocket?.readyState,
                  audioContextState: this.audioContext?.state,
                  processingIntervalActive: !!this.processingInterval,
                  timestamp: new Date().toISOString()
                });
                
                // Stop monitoring after 20 checks (10 seconds)
                if (monitoringCount >= 20) {
                  clearInterval(monitoringInterval);
                  console.log('üîç POST-STARTUP: Monitoring completed - service appears stable');
                }
              }, 500);
            } catch (setupError) {
              console.error('üö® CRASH in WebSocket onopen handler:', {
                error: setupError.message,
                stack: setupError.stack,
                timestamp: new Date().toISOString()
              });
              clearTimeout(connectionTimeout);
              reject(new Error(`WebSocket setup failed: ${setupError.message}`));
            }
          };
          console.log('üîó ‚úÖ onopen handler set successfully');
        } catch (onopenError) {
          console.error('üö® CRASH setting onopen handler:', {
            error: onopenError.message,
            stack: onopenError.stack,
            timestamp: new Date().toISOString()
          });
          reject(new Error(`Failed to set onopen handler: ${onopenError.message}`));
          return;
        }

        try {
          console.log('üîó Setting up onmessage handler...');
          this.websocket.onmessage = async (event) => {
            try {
              const crashDetector = {
                step: 'message-start',
                log: (step: string) => {
                  crashDetector.step = step;
                  debugLog(`üì• WEBSOCKET CRASH DETECTOR [${step}]`);
                }
              };
              
              crashDetector.log('message-received');
              debugLog('üì• WebSocket onmessage event triggered, data type:', typeof event.data);
              debugLog('üì• Message data size:', event.data instanceof Blob ? event.data.size : event.data instanceof ArrayBuffer ? event.data.byteLength : event.data.length);
              
              // Add a simple message counter
              if (!this.messageCount) {
                this.messageCount = 0;
              }
              this.messageCount++;
              debugLog(`üì• Processing message #${this.messageCount}`);
              
              crashDetector.log('handle-message-call');
              await this.handleWebSocketMessage(event.data);
              
              crashDetector.log('message-complete');
              debugLog(`üì• Message #${this.messageCount} handled successfully`);
            } catch (messageError) {
              console.error('üö® CRASH in WebSocket onmessage handler:', {
                error: messageError.message,
                stack: messageError.stack,
                dataType: typeof event.data,
                timestamp: new Date().toISOString(),
                step: (messageError as Error & { step?: string }).step || 'unknown'
              });
              // Don't reject here, just log the error to avoid crashing the connection
              if (this.errorCallback) {
                this.errorCallback(new Error(`WebSocket message handling error: ${messageError.message}`));
              }
            }
          };
          console.log('üîó ‚úÖ onmessage handler set successfully');
        } catch (onmessageError) {
          console.error('üö® CRASH setting onmessage handler:', {
            error: onmessageError.message,
            stack: onmessageError.stack,
            timestamp: new Date().toISOString()
          });
          reject(new Error(`Failed to set onmessage handler: ${onmessageError.message}`));
          return;
        }

        try {
          console.log('üîó Setting up onerror handler...');
          this.websocket.onerror = (error) => {
            try {
              console.error('üö® WebSocket onerror event triggered:', error);
              console.error('‚ùå WebSocket error:', error);
              console.error('üîó WebSocket state when error occurred:', this.websocket?.readyState);
              clearTimeout(connectionTimeout);
              
              // Provide more specific error messages
              if (this.websocket?.readyState === WebSocket.CONNECTING) {
                reject(new Error('Failed to connect to Gemini Live. Please check your API key and internet connection.'));
              } else {
                reject(new Error('WebSocket connection error occurred'));
              }
            } catch (errorHandlerError) {
              console.error('üö® CRASH in WebSocket onerror handler:', {
                error: errorHandlerError.message,
                stack: errorHandlerError.stack,
                originalError: error,
                timestamp: new Date().toISOString()
              });
              reject(new Error(`WebSocket error handler failed: ${errorHandlerError.message}`));
            }
          };
          console.log('üîó ‚úÖ onerror handler set successfully');
        } catch (onerrorError) {
          console.error('üö® CRASH setting onerror handler:', {
            error: onerrorError.message,
            stack: onerrorError.stack,
            timestamp: new Date().toISOString()
          });
          reject(new Error(`Failed to set onerror handler: ${onerrorError.message}`));
          return;
        }

        try {
          console.log('üîó Setting up onclose handler...');
          this.websocket.onclose = (event) => {
            console.log('üîå Gemini Live WebSocket closed:', event.code, event.reason);
            clearTimeout(connectionTimeout);
            
            console.log('üîå Close event details:', {
              code: event.code,
              reason: event.reason,
              wasClean: event.wasClean,
              isStreaming: this._isStreaming
            });
            
            // Log specific close codes for debugging
            if (event.code === 4003) {
              console.error('üö® WebSocket closed: API quota exceeded');
            } else if (event.code === 4400) {
              console.error('üö® WebSocket closed: Bad request - likely audio format issue');
            } else if (event.code === 1000) {
              console.log('‚úÖ WebSocket closed normally');
            } else {
              console.warn(`‚ö†Ô∏è WebSocket closed with code ${event.code}: ${event.reason}`);
            }
            
            if (this._isStreaming) {
              // Unexpected close - provide more detailed error information
              let errorMessage = 'Connection to Gemini Live lost';
              
              // Provide specific error messages based on close codes
              switch (event.code) {
                case 1000:
                  errorMessage = 'Gemini Live connection closed normally';
                  break;
                case 1001:
                  errorMessage = 'Gemini Live server is going away';
                  break;
                case 1002:
                  errorMessage = 'Gemini Live protocol error';
                  break;
                case 1003:
                  errorMessage = 'Gemini Live received unsupported data';
                  break;
                case 1006:
                  errorMessage = 'Gemini Live connection lost abnormally (network issue)';
                  break;
                case 1011:
                  errorMessage = 'Gemini Live server encountered an error';
                  break;
                case 1012:
                  errorMessage = 'Gemini Live server is restarting';
                  break;
                case 1013:
                  errorMessage = 'Gemini Live server is temporarily overloaded';
                  break;
                case 1014:
                  errorMessage = 'Gemini Live bad gateway';
                  break;
                case 1015:
                  errorMessage = 'Gemini Live TLS handshake failed';
                  break;
                case 4001:
                  errorMessage = 'Invalid API key for Gemini Live';
                  break;
                case 4003:
                  errorMessage = 'API quota exceeded for Gemini Live';
                  break;
                default:
                  errorMessage = `Gemini Live connection closed with code ${event.code}: ${event.reason || 'Unknown reason'}`;
              }
              
              if (this.errorCallback) {
                this.errorCallback(new Error(errorMessage));
              }
            }
            this._isStreaming = false;
          };
          console.log('üîó ‚úÖ onclose handler set successfully');
        } catch (oncloseError) {
          console.error('üö® CRASH setting onclose handler:', {
            error: oncloseError.message,
            stack: oncloseError.stack,
            timestamp: new Date().toISOString()
          });
          reject(new Error(`Failed to set onclose handler: ${oncloseError.message}`));
          return;
        }

        console.log('üîó ‚úÖ All WebSocket event handlers set successfully');

        // Validate WebSocket state after setting handlers
        try {
          console.log('üîó Validating WebSocket state after handler setup...');
          if (!this.websocket) {
            throw new Error('WebSocket instance became null after handler setup');
          }
          
          console.log('üîó WebSocket validation:', {
            readyState: this.websocket.readyState,
            readyStateText: this.getReadyStateText(this.websocket.readyState),
            url: this.websocket.url ? this.websocket.url.replace(this.apiKey, '[API_KEY_HIDDEN]') : 'undefined'
          });
          
          if (this.websocket.readyState === WebSocket.CLOSED) {
            throw new Error('WebSocket closed immediately after creation');
          }
          
          console.log('üîó ‚úÖ WebSocket state validation passed');
        } catch (validationError) {
          console.error('üö® CRASH during WebSocket validation:', {
            error: validationError.message,
            stack: validationError.stack,
            timestamp: new Date().toISOString()
          });
          reject(new Error(`WebSocket validation failed: ${validationError.message}`));
          return;
        }

        console.log('üîó ‚úÖ WebSocket connection setup completed successfully');

        // Add immediate connection monitoring
        console.log('üîó Starting immediate connection monitoring...');
        let connectionCheckCount = 0;
        const connectionMonitor = setInterval(() => {
          connectionCheckCount++;
          console.log(`üîó CONNECTION CHECK #${connectionCheckCount}:`, {
            readyState: this.websocket?.readyState,
            readyStateText: this.getReadyStateText(this.websocket?.readyState || -1),
            timestamp: new Date().toISOString()
          });
          
          // Stop monitoring after connection is established or fails
          if (this.websocket?.readyState === WebSocket.OPEN) {
            console.log('üîó ‚úÖ Connection established, stopping monitor');
            clearInterval(connectionMonitor);
          } else if (this.websocket?.readyState === WebSocket.CLOSED) {
            console.error('üîó ‚ùå Connection failed, stopping monitor');
            clearInterval(connectionMonitor);
          } else if (connectionCheckCount >= 20) { // 10 seconds
            console.error('üîó ‚è∞ Connection timeout, stopping monitor');
            clearInterval(connectionMonitor);
          }
        }, 500); // Check every 500ms

      } catch (error) {
        console.error('‚ùå Error creating WebSocket:', error);
        reject(new Error(`Failed to create WebSocket connection: ${error.message}`));
      }
    });
  }

  private sendInitialConfig(options: Required<GeminiLiveOptions>): void {
    try {
      console.log('üì§ sendInitialConfig called');
      
      if (!this.websocket || this.websocket.readyState !== WebSocket.OPEN) {
        console.warn('‚ö†Ô∏è WebSocket not ready for initial config');
        return;
      }

      console.log('üì§ Creating setup message...');
      // Send setup message for Live API - corrected format based on official docs
      const setupMessage = {
        setup: {
          model: "models/gemini-2.0-flash-live-001",
          generationConfig: {
            responseModalities: ["TEXT"],
            candidateCount: 1,
            maxOutputTokens: 8192,
            temperature: 0.7,
            topP: 0.95,
            topK: 40
          },
          realtimeInputConfig: {
            automaticActivityDetection: {
              disabled: false,
              startOfSpeechSensitivity: "START_SENSITIVITY_HIGH",
              endOfSpeechSensitivity: "END_SENSITIVITY_HIGH",
              prefixPaddingMs: 300,
              silenceDurationMs: 1000
            },
            activityHandling: "START_OF_ACTIVITY_INTERRUPTS",
            turnCoverage: "TURN_INCLUDES_ONLY_ACTIVITY"
          },
          inputAudioTranscription: {}
        }
      };

      console.log('üì§ Setup message created:', JSON.stringify(setupMessage, null, 2));
      console.log('üì§ Sending setup message to WebSocket...');
      
      this.websocket.send(JSON.stringify(setupMessage));
      console.log('üì§ Sent initial setup to Gemini Live API with corrected format');
    } catch (configError) {
      console.error('üö® CRASH in sendInitialConfig:', {
        error: configError.message,
        stack: configError.stack,
        websocketState: this.websocket?.readyState || 'null',
        timestamp: new Date().toISOString()
      });
      
      // Re-throw the error so the calling function can handle it
      throw new Error(`Initial config failed: ${configError.message}`);
    }
  }

  private startAudioProcessing(): void {
    try {
      console.log('üéµ Starting audio processing interval...');
      
      // Validate prerequisites
      if (!this.audioAccumulationBuffer) {
        throw new Error('Audio accumulation buffer not initialized');
      }
      
      if (!this.audioChunksBuffer) {
        throw new Error('Audio chunks buffer not initialized');
      }
      
      console.log('üéµ Audio processing prerequisites validated');
      
      // Try a simplified approach first
      const simplifiedMode = true; // Set to false to use original complex approach
      
      if (simplifiedMode) {
        console.log('üéµ Using simplified audio processing approach...');
        this.startSimplifiedAudioProcessing();
        return;
      }
      
      let intervalCount = 0;
      
      console.log('üéµ Setting up audio processing interval...');
      // Process accumulated audio chunks every 100ms, but only send when enough time has passed
      this.processingInterval = window.setInterval(() => {
        try {
          intervalCount++;
          
          // Only log every 10th interval to reduce spam, but always log the first few
          if (intervalCount <= 5 || intervalCount % 10 === 0) {
            console.log(`üéµ Audio processing interval #${intervalCount} triggered`);
            console.log(`üéµ Current audio buffer state: accumulation=${this.audioAccumulationBuffer.length}, processing=${this.audioChunksBuffer.length}`);
          }
          
          this.checkAndProcessAccumulatedAudio();
          
          // Only log completion for first few intervals or every 10th
          if (intervalCount <= 5 || intervalCount % 10 === 0) {
            console.log(`üéµ Audio processing interval #${intervalCount} completed successfully`);
          }
        } catch (intervalError) {
          console.error(`üö® CRASH in audio processing interval #${intervalCount}:`, {
            error: intervalError.message,
            stack: intervalError.stack,
            timestamp: new Date().toISOString()
          });
          
          // Try to continue processing despite the error
          if (this.errorCallback) {
            this.errorCallback(new Error(`Audio processing interval error: ${intervalError.message}`));
          }
        }
      }, 100);
      
      console.log('üéµ ‚úÖ Audio processing interval set successfully');
      
      console.log('üéµ Starting connection health monitoring...');
      // Add connection health monitoring
      this.startConnectionHealthCheck();
      console.log('üéµ ‚úÖ Connection health monitoring started');
      
      console.log('üéµ ‚úÖ Audio processing setup completed successfully');
      
      // Add immediate diagnostic check
      setTimeout(() => {
        console.log('üîç DIAGNOSTIC: Checking audio processing state after 2 seconds...');
        console.log('üîç DIAGNOSTIC: Processing interval active:', !!this.processingInterval);
        console.log('üîç DIAGNOSTIC: Audio context state:', this.audioContext?.state);
        console.log('üîç DIAGNOSTIC: Audio processor connected:', !!this.audioProcessor);
        console.log('üîç DIAGNOSTIC: Audio stream active:', !!this.audioStream);
        console.log('üîç DIAGNOSTIC: Audio accumulation buffer size:', this.audioAccumulationBuffer?.length || 0);
        console.log('üîç DIAGNOSTIC: WebSocket state:', this.websocket?.readyState, this.getReadyStateText(this.websocket?.readyState || -1));
        console.log('üîç DIAGNOSTIC: Is streaming:', this._isStreaming);
        
        // Test if the interval is actually running
        let testIntervalCount = 0;
        const testInterval = setInterval(() => {
          testIntervalCount++;
          console.log(`üîç DIAGNOSTIC: Test interval #${testIntervalCount} - intervals are working`);
          if (testIntervalCount >= 3) {
            clearInterval(testInterval);
            console.log('üîç DIAGNOSTIC: Test interval completed - intervals are functional');
          }
        }, 500);
      }, 2000);
    } catch (audioProcessingError) {
      console.error('üö® CRASH in startAudioProcessing:', {
        error: audioProcessingError.message,
        stack: audioProcessingError.stack,
        timestamp: new Date().toISOString()
      });
      
      // Re-throw the error so the calling function can handle it
      throw new Error(`Audio processing setup failed: ${audioProcessingError.message}`);
    }
  }

  private startSimplifiedAudioProcessing(): void {
    console.log('üéµ SIMPLIFIED: Starting simplified audio processing...');
    
    try {
      // Instead of complex intervals, process audio immediately when it's available
      let intervalEventCount = 0;
      let lastAudioSent = 0;
      const SEND_INTERVAL_MS = 1000; // Send audio every 1 second
      const MAX_BUFFER_SIZE = 200; // Safety cap to prevent unbounded growth
      
      // Add heartbeat monitor to detect silent crashes
      let lastHeartbeat = Date.now();
      let lastBufferSize = 0;
      
      const heartbeatMonitor = window.setInterval(() => {
        const now = Date.now();
        const timeSinceLastHeartbeat = now - lastHeartbeat;
        const currentBufferSize = this.audioAccumulationBuffer?.length || 0;
        
        // Update heartbeat if buffer is growing (indicates audio activity)
        if (currentBufferSize > lastBufferSize) {
          lastHeartbeat = now;
          lastBufferSize = currentBufferSize;
          console.log(`üíì HEARTBEAT: Audio buffer growing: ${currentBufferSize} chunks`);
        }
        
        if (timeSinceLastHeartbeat > 5000) { // If no activity for 5 seconds
          console.warn(`üíî HEARTBEAT: No audio processing activity for ${timeSinceLastHeartbeat}ms`);
          console.warn(`üíî HEARTBEAT: Service state:`, {
            isStreaming: this._isStreaming,
            websocketState: this.websocket?.readyState,
            audioContextState: this.audioContext?.state,
            bufferSize: currentBufferSize,
            intervalEvents: intervalEventCount,
            timestamp: new Date().toISOString()
          });
        }
      }, 2000); // Check every 2 seconds
      
      // Set up a simple timer to check for audio and send it
      const simpleProcessor = window.setInterval(() => {
        try {
          const crashDetector = {
            step: 'interval-start',
            log: (step: string) => {
              crashDetector.step = step;
              if (intervalEventCount <= 10 || intervalEventCount % 100 === 0) {
                debugLog(`üéµ SIMPLIFIED CRASH DETECTOR [${step}] event #${intervalEventCount}`);
              }
            }
          };
          
          crashDetector.log('time-check');
          const now = Date.now();
          
          crashDetector.log('buffer-overflow-check');
          // Safety check: if buffers are getting too large, force a flush
          if (this.audioAccumulationBuffer.length > MAX_BUFFER_SIZE) {
            console.warn(`‚ö†Ô∏è BUFFER OVERFLOW: Forcing flush of ${this.audioAccumulationBuffer.length} chunks`);
            const chunksToProcess = [...this.audioAccumulationBuffer];
            this.audioAccumulationBuffer.length = 0; // Clear array efficiently
            this.processAudioChunksSimplified(chunksToProcess);
            lastAudioSent = now;
            return;
          }
          
          crashDetector.log('audio-processing-check');
          // Only process if we have audio and enough time has passed
          if (this.audioAccumulationBuffer.length > 0 && 
              (now - lastAudioSent) >= SEND_INTERVAL_MS) {
            
            console.log(`üéµ PROCESSING: Found ${this.audioAccumulationBuffer.length} chunks, sending to API`);
            
            crashDetector.log('logging-decision');
            // Only log occasionally to prevent console saturation
            if (intervalEventCount % 10 === 0) {
              debugLog(`üéµ SIMPLIFIED: Processing ${this.audioAccumulationBuffer.length} audio chunks`);
            }
            
            crashDetector.log('buffer-copy');
            // Move all accumulated audio to processing buffer
            const chunksToProcess = [...this.audioAccumulationBuffer];
            this.audioAccumulationBuffer.length = 0; // Clear array efficiently
            lastAudioSent = now;
            
            crashDetector.log('process-chunks-call');
            // Process immediately
            this.processAudioChunksSimplified(chunksToProcess);
          } else {
            // Log why we're not processing
            if (intervalEventCount <= 10 || intervalEventCount % 100 === 0) {
              const timeSinceLastSend = now - lastAudioSent;
              console.log(`üéµ WAITING: Buffer=${this.audioAccumulationBuffer.length}, timeSince=${timeSinceLastSend}ms, threshold=${SEND_INTERVAL_MS}ms`);
            }
          }
          
          crashDetector.log('event-counting');
          // Log audio event count very occasionally to reduce console spam
          if (intervalEventCount % 100 === 0) {
            debugLog(`üéµ SIMPLIFIED: Audio events received: ${intervalEventCount}, buffer size: ${this.audioAccumulationBuffer.length}`);
          }
          intervalEventCount++;
          
          crashDetector.log('interval-complete');
        } catch (processingError) {
          console.error('üö® SIMPLIFIED: Error in audio processing:', {
            error: processingError.message,
            stack: processingError.stack,
            timestamp: new Date().toISOString(),
            step: (processingError as Error & { step?: string }).step || 'unknown'
          });
          
          // Clear buffers on error to prevent corruption
          this.audioAccumulationBuffer.length = 0;
        }
      }, 100); // Check every 100ms
      
      // Store the interval for cleanup
      this.processingInterval = simpleProcessor;
      
      console.log('üéµ SIMPLIFIED: Simplified audio processing started');
      
    } catch (error) {
      console.error('üö® SIMPLIFIED: Failed to start simplified audio processing:', error);
      throw error;
    }
  }

  private async processAudioChunksSimplified(chunks: Blob[]): Promise<void> {
    // Only log occasionally to prevent console saturation
    if (Math.random() < 0.1) { // 10% chance to log
      console.log('üéµ SIMPLIFIED: Processing audio chunks directly...');
    }
    
    if (chunks.length === 0 || !this.websocket || this.websocket.readyState !== WebSocket.OPEN) {
      if (Math.random() < 0.01) { // 1% chance to log
        console.log('üéµ SIMPLIFIED: Skipping - no chunks or websocket not ready');
      }
      return;
    }

    try {
      if (Math.random() < 0.1) { // 10% chance to log
        console.log(`üéµ SIMPLIFIED: Processing ${chunks.length} chunks, total size: ${chunks.reduce((sum, chunk) => sum + chunk.size, 0)} bytes`);
      }

      // Combine all chunks into one buffer
      const totalSize = chunks.reduce((sum, chunk) => sum + chunk.size, 0);
      const combinedBuffer = new ArrayBuffer(totalSize);
      const combinedView = new Uint8Array(combinedBuffer);
      
      let offset = 0;
      for (const chunk of chunks) {
        const chunkBuffer = await chunk.arrayBuffer();
        const chunkView = new Uint8Array(chunkBuffer);
        combinedView.set(chunkView, offset);
        offset += chunkView.length;
      }
      
      // Convert to base64
      const base64Audio = this.arrayBufferToBase64(combinedBuffer);
      
      // Send to API
      const message = {
        realtimeInput: {
          audio: {
            data: base64Audio,
            mimeType: "audio/pcm;rate=16000"
          }
        }
      };

      this.websocket.send(JSON.stringify(message));
      
      // Add chunk sending counter for debugging
      console.count('üéµ AUDIO CHUNKS SENT');
      
      if (Math.random() < 0.1) { // 10% chance to log
        console.log(`üéµ SIMPLIFIED: Sent ${base64Audio.length} characters of audio data`);
      }
      
    } catch (error) {
      console.error('üö® SIMPLIFIED: Error processing audio chunks:', error);
    } finally {
      // Always clear the chunks array to prevent memory leaks
      chunks.length = 0;
    }
  }

  private checkAndProcessAccumulatedAudio(): void {
    try {
      const now = Date.now();
      const timeSinceLastProcess = now - this.lastProcessTime;
      
      // Log buffer state and timing every few checks
      const shouldLogDetails = this.audioAccumulationBuffer.length > 0 || timeSinceLastProcess > this.ACCUMULATION_TIME_MS;
      
      if (shouldLogDetails) {
        console.log(`üéµ Checking accumulated audio: ${this.audioAccumulationBuffer.length} chunks, last process: ${timeSinceLastProcess}ms ago (threshold: ${this.ACCUMULATION_TIME_MS}ms)`);
      }
      
      // Only process if we have chunks and enough time has passed since last processing
      if (this.audioAccumulationBuffer.length > 0 && 
          timeSinceLastProcess >= this.ACCUMULATION_TIME_MS) {
        
        console.log(`üéµ ‚úÖ PROCESSING ${this.audioAccumulationBuffer.length} accumulated chunks (${timeSinceLastProcess}ms since last process)`);
        
        // Move accumulated chunks to processing buffer
        this.audioChunksBuffer = [...this.audioAccumulationBuffer];
        this.audioAccumulationBuffer = [];
        this.lastProcessTime = now;
        
        // Process the accumulated chunks
        this.processAudioChunks();
      } else if (this.audioAccumulationBuffer.length === 0) {
        // Only log this occasionally to avoid spam
        if (Math.random() < 0.01) { // 1% chance to log
          console.log('üéµ No audio chunks to process');
        }
      } else {
        // Log when we're waiting for more time to pass
        if (shouldLogDetails) {
          console.log(`üéµ Waiting for accumulation time (${timeSinceLastProcess}ms < ${this.ACCUMULATION_TIME_MS}ms)`);
        }
      }
    } catch (checkError) {
      console.error('üö® CRASH in checkAndProcessAccumulatedAudio:', {
        error: checkError.message,
        stack: checkError.stack,
        timestamp: new Date().toISOString(),
        bufferLength: this.audioAccumulationBuffer?.length || 0
      });
      
      // Try to continue processing despite the error
      if (this.errorCallback) {
        this.errorCallback(new Error(`Audio accumulation check error: ${checkError.message}`));
      }
    }
  }

  private startConnectionHealthCheck(): void {
    try {
      console.log('üîç Setting up connection health check...');
      
      // Check connection health every 5 seconds
      const healthCheckInterval = setInterval(() => {
        try {
          if (this.websocket) {
            console.log('üîç WebSocket health check:', {
              readyState: this.websocket.readyState,
              readyStateText: this.getReadyStateText(this.websocket.readyState),
              isStreaming: this._isStreaming
            });
            
            // If connection is closed but we're still supposed to be streaming, that's an issue
            if (this.websocket.readyState === WebSocket.CLOSED && this._isStreaming) {
              console.error('üö® WebSocket connection lost while streaming!');
            }
          }
          
          // Memory usage monitoring
          if (typeof performance !== 'undefined' && 'memory' in performance) {
            const memory = (performance as { memory: { usedJSHeapSize: number; totalJSHeapSize: number; jsHeapSizeLimit: number } }).memory;
            const memInfo = {
              usedJSHeapSize: Math.round(memory.usedJSHeapSize / 1024 / 1024),
              totalJSHeapSize: Math.round(memory.totalJSHeapSize / 1024 / 1024),
              jsHeapSizeLimit: Math.round(memory.jsHeapSizeLimit / 1024 / 1024),
              audioBufferLength: this.audioAccumulationBuffer?.length || 0,
              processingBufferLength: this.audioChunksBuffer?.length || 0
            };
            
            console.log('üíæ Memory usage:', memInfo);
            
            // Warn if memory usage is getting high
            if (memInfo.usedJSHeapSize > memInfo.jsHeapSizeLimit * 0.8) {
              console.warn('‚ö†Ô∏è High memory usage detected! This could cause crashes.');
            }
            
            // Warn if audio buffers are getting too large
            if (memInfo.audioBufferLength > 100) {
              console.warn('‚ö†Ô∏è Audio accumulation buffer is getting large:', memInfo.audioBufferLength);
            }
            
            if (memInfo.processingBufferLength > 50) {
              console.warn('‚ö†Ô∏è Audio processing buffer is getting large:', memInfo.processingBufferLength);
            }
          }
          
          // Clean up if not streaming
          if (!this._isStreaming) {
            clearInterval(healthCheckInterval);
          }
        } catch (healthCheckError) {
          console.error('üö® Error in health check:', healthCheckError);
        }
      }, 5000);
      
      console.log('üîç ‚úÖ Connection health check setup completed');
    } catch (healthCheckSetupError) {
      console.error('üö® CRASH in startConnectionHealthCheck:', {
        error: healthCheckSetupError.message,
        stack: healthCheckSetupError.stack,
        timestamp: new Date().toISOString()
      });
      
      // Don't re-throw this error as health check is not critical
      console.warn('‚ö†Ô∏è Health check setup failed, continuing without health monitoring');
    }
  }

  private getReadyStateText(readyState: number): string {
    switch (readyState) {
      case WebSocket.CONNECTING: return 'CONNECTING';
      case WebSocket.OPEN: return 'OPEN';
      case WebSocket.CLOSING: return 'CLOSING';
      case WebSocket.CLOSED: return 'CLOSED';
      default: return 'UNKNOWN';
    }
  }

  private calculateAudioLevel(audioData: Float32Array): number {
    // Calculate RMS (Root Mean Square) to get audio level
    let sum = 0;
    for (let i = 0; i < audioData.length; i++) {
      sum += audioData[i] * audioData[i];
    }
    return Math.sqrt(sum / audioData.length);
  }

  private async processAudioChunks(): Promise<void> {
    console.log('üéµ processAudioChunks called');
    
    if (this.audioChunksBuffer.length === 0 || !this.websocket || this.websocket.readyState !== WebSocket.OPEN) {
      console.log('üéµ Skipping audio processing - no chunks or websocket not ready');
      return;
    }

    try {
      console.log('üéµ Starting audio chunk processing...');
      
      // Get all pending chunks
      const chunks = [...this.audioChunksBuffer];
      this.audioChunksBuffer = [];

      console.log(`üéµ Processing ${chunks.length} accumulated PCM chunks, total size: ${chunks.reduce((sum, chunk) => sum + chunk.size, 0)} bytes`);

      // Convert accumulated PCM chunks to a single ArrayBuffer
      // Since we're now capturing raw PCM data, no conversion is needed
      const totalSize = chunks.reduce((sum, chunk) => sum + chunk.size, 0);
      console.log(`üéµ Creating combined buffer of size: ${totalSize}`);
      
      const combinedBuffer = new ArrayBuffer(totalSize);
      const combinedView = new Uint8Array(combinedBuffer);
      
      console.log('üéµ Combining chunks into single buffer...');
      let offset = 0;
      for (let i = 0; i < chunks.length; i++) {
        try {
          const chunk = chunks[i];
          console.log(`üéµ Processing chunk ${i + 1}/${chunks.length}, size: ${chunk.size}`);
          
          const chunkBuffer = await chunk.arrayBuffer();
          const chunkView = new Uint8Array(chunkBuffer);
          combinedView.set(chunkView, offset);
          offset += chunkView.length;
          
          console.log(`üéµ Chunk ${i + 1} processed, offset now: ${offset}`);
        } catch (chunkError) {
          console.error(`üö® Error processing chunk ${i + 1}:`, chunkError);
          // Continue with other chunks
        }
      }
      
      console.log('üéµ Converting to base64...');
      // Convert PCM data to base64 as required by Live API
      const base64Audio = this.arrayBufferToBase64(combinedBuffer);
      console.log(`üéµ Base64 conversion complete: ${base64Audio.length} characters`);

      // Send realtime input to Gemini Live API using PCM format
      const message = {
        realtimeInput: {
          audio: {
            data: base64Audio,
            mimeType: "audio/pcm;rate=16000"
          }
        }
      };

      console.log('üéµ Sending audio message to WebSocket...');
      this.websocket.send(JSON.stringify(message));
      console.log(`üì§ Sent raw PCM audio chunk: ${base64Audio.length} characters (${combinedBuffer.byteLength} bytes) as audio/pcm;rate=16000`);
      console.log(`üì§ WebSocket readyState after send: ${this.websocket.readyState} (${this.getReadyStateText(this.websocket.readyState)})`);
      
      // Add a small delay to avoid overwhelming the API
      console.log('üéµ Adding processing delay...');
      await new Promise(resolve => setTimeout(resolve, 10));
      console.log('üéµ Audio chunk processing complete');

    } catch (error) {
      console.error('üö® CRASH in processAudioChunks:', {
        error: error.message,
        stack: error.stack,
        timestamp: new Date().toISOString(),
        chunksLength: this.audioChunksBuffer?.length || 0,
        websocketState: this.websocket?.readyState || 'null'
      });
      
      // If processing fails, we'll try again with the next batch
      if (this.errorCallback) {
        this.errorCallback(new Error(`Audio chunk processing error: ${error.message}`));
      }
    }
  }

  private arrayBufferToBase64(buffer: ArrayBuffer): string {
    try {
      console.log(`üîÑ Converting ArrayBuffer to base64: ${buffer.byteLength} bytes`);
      
      // Use Buffer for efficient base64 conversion instead of manual byte-by-byte string building
      const result = Buffer.from(buffer).toString('base64');
      console.log(`üîÑ Base64 conversion complete: ${result.length} characters`);
      
      return result;
    } catch (conversionError) {
      console.error('üö® CRASH in arrayBufferToBase64:', {
        error: conversionError.message,
        stack: conversionError.stack,
        bufferSize: buffer?.byteLength || 0,
        timestamp: new Date().toISOString()
      });
      
      // Return empty string to prevent further crashes
      return '';
    }
  }

  private async handleWebSocketMessage(data: string | Blob | ArrayBuffer): Promise<void> {
    try {
      console.log('üì• handleWebSocketMessage called, data type:', typeof data);
      
      let messageText: string;

      console.log('üì• Converting message data to text...');
      // Handle different data types
      if (typeof data === 'string') {
        messageText = data;
        console.log('üì• Data is already string, length:', data.length);
      } else if (data instanceof Blob) {
        console.log('üì• Converting Blob to text, size:', data.size);
        // Convert Blob to text
        messageText = await data.text();
        console.log('üì• Blob converted to text, length:', messageText.length);
      } else if (data instanceof ArrayBuffer) {
        console.log('üì• Converting ArrayBuffer to text, byteLength:', data.byteLength);
        // Convert ArrayBuffer to text
        const decoder = new TextDecoder();
        messageText = decoder.decode(data);
        console.log('üì• ArrayBuffer converted to text, length:', messageText.length);
      } else {
        console.warn('üì• Received unknown message type from Gemini Live:', typeof data);
        return;
      }

      // Skip empty messages
      if (!messageText || messageText.trim() === '') {
        console.log('üì• Skipping empty message');
        return;
      }

      console.log('üì• Parsing JSON response...');
      // Parse JSON response
      const response: GeminiLiveResponse = JSON.parse(messageText);
      console.log('üì• JSON parsed successfully');
      
      // Log all responses for debugging (but limit size for readability)
      const responseStr = JSON.stringify(response, null, 2);
      if (responseStr.length > 500) {
        console.log('üì• Received Gemini Live response (truncated):', responseStr.substring(0, 500) + '...');
      } else {
        console.log('üì• Received Gemini Live response:', responseStr);
      }

      console.log('üì• Processing response content...');
      // Handle setup complete
      if (response.setupComplete) {
        console.log('üîó Gemini Live setup completed');
        console.log('üîó Setup completion received - API is ready for audio input');
        return;
      }

      // Handle server content
      if (response.serverContent) {
        console.log('üì• Processing server content...');
        const serverContent = response.serverContent;
        console.log('üìã Server content received:', JSON.stringify(serverContent, null, 2));
        
        // Handle model turn (text response)
        if (serverContent.modelTurn && serverContent.modelTurn.parts) {
          console.log('ü§ñ Model turn detected with parts:', serverContent.modelTurn.parts);
          for (const part of serverContent.modelTurn.parts) {
            if (part.text && this.resultCallback) {
              console.log('üìù Calling result callback with model text:', part.text);
              this.resultCallback({
                transcript: part.text,
                isFinal: serverContent.turnComplete || false,
                speakerTag: undefined,
                confidence: 1.0
              });
            }
          }
        }

        // Handle input transcription
        if (serverContent.inputTranscription && this.resultCallback) {
          console.log('üé§ Input transcription received:', serverContent.inputTranscription.text, 'finished:', serverContent.inputTranscription.finished);
          this.resultCallback({
            transcript: serverContent.inputTranscription.text,
            isFinal: serverContent.inputTranscription.finished || false,
            speakerTag: undefined,
            confidence: 1.0
          });
        }
        
        // Handle output transcription (if any)
        if (serverContent.outputTranscription && this.resultCallback) {
          console.log('üîä Output transcription received:', serverContent.outputTranscription.text, 'finished:', serverContent.outputTranscription.finished);
          this.resultCallback({
            transcript: serverContent.outputTranscription.text,
            isFinal: serverContent.outputTranscription.finished || false,
            speakerTag: undefined,
            confidence: 1.0
          });
        }
      }

      // Handle errors
      if (response.error) {
        console.error('üì• Gemini Live API error received:', response.error);
        if (this.errorCallback) {
          this.errorCallback(new Error(response.error.message || 'Unknown error'));
        }
        return;
      }

      console.log('üì• Message processing completed successfully');

    } catch (error) {
      console.error('üö® CRASH in handleWebSocketMessage:', {
        error: error.message,
        stack: error.stack,
        dataType: typeof data,
        dataSize: data instanceof Blob ? data.size : data instanceof ArrayBuffer ? data.byteLength : typeof data === 'string' ? data.length : 'unknown',
        timestamp: new Date().toISOString()
      });
      
      console.error('üì• Raw data type:', typeof data);
      console.error('üì• Raw data (first 200 chars):', typeof data === 'string' ? data.substring(0, 200) : 'Non-string data');
      
      // Don't re-throw the error to avoid crashing the WebSocket connection
      if (this.errorCallback) {
        this.errorCallback(new Error(`Message handling error: ${error.message}`));
      }
    }
  }

  // Simplified test mode for debugging
  private async startTestMode(options: GeminiLiveOptions = {}): Promise<void> {
    console.log('üß™ TEST MODE: Starting simplified WebSocket test...');
    
    try {
      if (!this._isAvailable) {
        throw new Error('Gemini Live service is not available');
      }

      if (!this.apiKey) {
        throw new Error('Gemini API key not configured');
      }

      console.log('üß™ TEST MODE: Creating WebSocket connection...');
      const wsUrl = `wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1beta.GenerativeService.BidiGenerateContent?key=${this.apiKey}`;
      
      this.websocket = new WebSocket(wsUrl);
      
      return new Promise((resolve, reject) => {
        if (!this.websocket) {
          reject(new Error('Failed to create WebSocket'));
          return;
        }

        this.websocket.onopen = () => {
          console.log('üß™ TEST MODE: WebSocket connected');
          
          // Send simple setup message
          const setupMessage = {
            setup: {
              model: "models/gemini-2.0-flash-live-001",
              generationConfig: {
                responseModalities: ["TEXT"]
              }
            }
          };
          
          console.log('üß™ TEST MODE: Sending setup message...');
          this.websocket!.send(JSON.stringify(setupMessage));
          
          this._isStreaming = true;
          console.log('üß™ TEST MODE: Setup complete');
          
          // Send a test audio message to verify the API can process audio
          console.log('üß™ TEST MODE: Sending test audio message...');
          const testAudioMessage = {
            realtimeInput: {
              audio: {
                data: "UklGRiQAAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0YQAAAAA=", // Empty WAV file in base64
                mimeType: "audio/pcm;rate=16000"
              }
            }
          };
          
          this.websocket!.send(JSON.stringify(testAudioMessage));
          console.log('üß™ TEST MODE: Test audio message sent');
          
          resolve();
        };

        this.websocket.onmessage = async (event) => {
          console.log('üß™ TEST MODE: Received message:', event.data);
          
          try {
            let messageText: string;
            
            // Handle different data types
            if (typeof event.data === 'string') {
              messageText = event.data;
              console.log('üß™ TEST MODE: Message is string, length:', event.data.length);
            } else if (event.data instanceof Blob) {
              console.log('üß™ TEST MODE: Message is Blob, converting to text...');
              messageText = await event.data.text();
              console.log('üß™ TEST MODE: Blob converted to text, length:', messageText.length);
            } else {
              console.warn('üß™ TEST MODE: Unknown message type:', typeof event.data);
              return;
            }
            
            // Skip empty messages
            if (!messageText || messageText.trim() === '') {
              console.log('üß™ TEST MODE: Skipping empty message');
              return;
            }
            
            console.log('üß™ TEST MODE: Message text:', messageText);
            
            const response = JSON.parse(messageText);
            if (response.setupComplete) {
              console.log('üß™ TEST MODE: Setup completed by API');
              
              // Send a test audio message to verify the API can process audio
              console.log('üß™ TEST MODE: Sending test audio message...');
              const testAudioMessage = {
                realtimeInput: {
                  audio: {
                    data: "UklGRiQAAABXQVZFZm10IBAAAAABAAEARKwAAIhYAQACABAAZGF0YQAAAAA=", // Empty WAV file in base64
                    mimeType: "audio/pcm;rate=16000"
                  }
                }
              };
              
              this.websocket!.send(JSON.stringify(testAudioMessage));
              console.log('üß™ TEST MODE: Test audio message sent');
            }
            if (response.error) {
              console.error('üß™ TEST MODE: API error:', response.error);
            }
            if (response.serverContent) {
              console.log('üß™ TEST MODE: Server content received:', response.serverContent);
            }
          } catch (parseError) {
            console.warn('üß™ TEST MODE: Could not parse message:', parseError);
            console.warn('üß™ TEST MODE: Raw message data:', event.data);
          }
        };

        this.websocket.onerror = (error) => {
          console.error('üß™ TEST MODE: WebSocket error:', error);
          reject(new Error('WebSocket connection failed'));
        };

        this.websocket.onclose = (event) => {
          console.log('üß™ TEST MODE: WebSocket closed:', event.code, event.reason);
          this._isStreaming = false;
        };

        // Set timeout
        setTimeout(() => {
          if (this.websocket?.readyState === WebSocket.CONNECTING) {
            reject(new Error('Connection timeout'));
          }
        }, 10000);
      });
      
    } catch (error) {
      console.error('üß™ TEST MODE: Error:', error);
      throw error;
    }
  }

  stopStreaming(): void {
    if (!this._isStreaming) {
      return;
    }

    console.log('üõë Stopping Gemini Live streaming');
    this.cleanup();
    this._isStreaming = false;
  }

  cleanup(): void {
    console.log('üßπ Starting Gemini Live cleanup...');
    
    try {
      // Clear audio buffers
      this.audioChunksBuffer = [];
      this.audioAccumulationBuffer = [];
      
      // Stop audio processing
      if (this.processingInterval) {
        clearInterval(this.processingInterval);
        this.processingInterval = null;
        console.log('‚úÖ Audio processing interval cleared');
      }

      // Clean up Web Audio API resources
      if (this.audioProcessor) {
        try {
          this.audioProcessor.disconnect();
          this.audioProcessor = null;
          console.log('‚úÖ Audio processor disconnected');
        } catch (processorError) {
          console.warn('Warning: Error disconnecting audio processor:', processorError);
        }
      }
      
      if (this.audioContext) {
        try {
          // Check if context is not already closed
          if (this.audioContext.state !== 'closed') {
            this.audioContext.close();
            console.log('‚úÖ AudioContext closed');
          }
          this.audioContext = null;
        } catch (contextError) {
          console.warn('Warning: Error closing AudioContext:', contextError);
        }
      }

      // Stop audio stream
      if (this.audioStream) {
        try {
          this.audioStream.getTracks().forEach(track => {
            try {
              track.stop();
            } catch (trackError) {
              console.warn('Warning: Error stopping audio track:', trackError);
            }
          });
          this.audioStream = null;
          console.log('‚úÖ Audio stream stopped');
        } catch (streamError) {
          console.warn('Warning: Error stopping audio stream:', streamError);
        }
      }

      // Close WebSocket
      if (this.websocket) {
        try {
          if (this.websocket.readyState === WebSocket.OPEN || this.websocket.readyState === WebSocket.CONNECTING) {
            this.websocket.close();
            console.log('‚úÖ WebSocket closed');
          }
          this.websocket = null;
        } catch (wsError) {
          console.warn('Warning: Error closing WebSocket:', wsError);
        }
      }

      console.log('üßπ Gemini Live cleanup completed');
    } catch (error) {
      console.error('‚ùå Error during cleanup:', error);
      // Continue cleanup even if there are errors
    }
  }

  onResult(callback: (result: GeminiLiveResult) => void): void {
    this.resultCallback = callback;
  }

  onError(callback: (error: Error) => void): void {
    this.errorCallback = callback;
  }

  // Method to reinitialize when settings change
  async reinitialize(): Promise<void> {
    await this.checkAvailability();
  }
}

// Export singleton instance
export const geminiLiveService = new GeminiLiveServiceImpl();
export default geminiLiveService; 